{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next-Word-Prediction",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0aYGy5e2t4qrm4NKAQRX4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaiahMohamedAmine/Next-Word-Prediction/blob/master/Next_Word_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUzQ0rqgHBi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "import tensorflow.keras.utils as ku "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvVfsr2IHwQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f92fc9b6-53a3-41f4-86ff-ee780d0aabc5"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-23 21:47:57--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.128, 108.177.119.128, 108.177.126.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-07-23 21:47:57 (81.9 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27a430KXIHXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "aad695a6-9af9-497a-81ee-b18afd4576df"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index )+ 1\n",
        "\n",
        "input_sentences =[]\n",
        "for row in corpus :\n",
        "  token_sentence = tokenizer.texts_to_sequences([row])[0]\n",
        "  for i in range(1,len(token_sentence)) :\n",
        "    sentence = token_sentence[:i+1]\n",
        "    input_sentences.append(sentence)\n",
        "\n",
        "input_sentences = np.array(input_sentences)\n",
        "padded = pad_sequences (input_sentences,padding='pre')\n",
        "\n",
        "predictors, labels = padded[:, :-1], padded[ :, -1]\n",
        "\n",
        "labels = ku.to_categorical(labels,num_classes=total_words)\n",
        "print(predictors.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15462, 10)\n",
            "(15462, 3211)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2W7jA_iKMhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "300adbec-7e22-4170-8d6b-701fe0b1c1e7"
      },
      "source": [
        "input_length = len (predictors[0])\n",
        "print(total_words)\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(total_words,100,input_length=input_length),\n",
        "                             tf.keras.layers.LSTM(150),\n",
        "                           #  tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dropout(0.2),\n",
        "                             tf.keras.layers.Dense(total_words/2, activation='relu'),\n",
        "                             tf.keras.layers.Dense(total_words, activation='softmax') \n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer =\"adam\", metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3211\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 150)               150600    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1605)              242355    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 5,870,921\n",
            "Trainable params: 5,870,921\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ZGmJbsQCaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a62c5b1-3463-40d6-9e25-29fbc14f8827"
      },
      "source": [
        "history = model.fit(predictors,labels,epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 6.8059 - acc: 0.0243\n",
            "Epoch 2/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 6.3941 - acc: 0.0341\n",
            "Epoch 3/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 6.0945 - acc: 0.0455\n",
            "Epoch 4/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 5.7217 - acc: 0.0630\n",
            "Epoch 5/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 5.3374 - acc: 0.0823\n",
            "Epoch 6/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 4.9512 - acc: 0.1013\n",
            "Epoch 7/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 4.5173 - acc: 0.1324\n",
            "Epoch 8/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 4.0322 - acc: 0.1722\n",
            "Epoch 9/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.5093 - acc: 0.2391\n",
            "Epoch 10/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.0092 - acc: 0.3175\n",
            "Epoch 11/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.5836 - acc: 0.3981\n",
            "Epoch 12/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.2336 - acc: 0.4724\n",
            "Epoch 13/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.9715 - acc: 0.5272\n",
            "Epoch 14/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.7662 - acc: 0.5683\n",
            "Epoch 15/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.5862 - acc: 0.6053\n",
            "Epoch 16/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.4471 - acc: 0.6334\n",
            "Epoch 17/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.3131 - acc: 0.6663\n",
            "Epoch 18/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.2134 - acc: 0.6895\n",
            "Epoch 19/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.1489 - acc: 0.7042\n",
            "Epoch 20/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0665 - acc: 0.7269\n",
            "Epoch 21/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0050 - acc: 0.7374\n",
            "Epoch 22/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9656 - acc: 0.7488\n",
            "Epoch 23/100\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9194 - acc: 0.7595\n",
            "Epoch 24/100\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.8837 - acc: 0.7690\n",
            "Epoch 25/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.8449 - acc: 0.7799\n",
            "Epoch 26/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.8325 - acc: 0.7812\n",
            "Epoch 27/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.7943 - acc: 0.7921\n",
            "Epoch 28/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.7712 - acc: 0.7953\n",
            "Epoch 29/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.7620 - acc: 0.7985\n",
            "Epoch 30/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.7511 - acc: 0.8005\n",
            "Epoch 31/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.7506 - acc: 0.8001\n",
            "Epoch 32/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.7136 - acc: 0.8112\n",
            "Epoch 33/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.7018 - acc: 0.8134\n",
            "Epoch 34/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6905 - acc: 0.8148\n",
            "Epoch 35/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6881 - acc: 0.8144\n",
            "Epoch 36/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6775 - acc: 0.8176\n",
            "Epoch 37/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6574 - acc: 0.8218\n",
            "Epoch 38/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6646 - acc: 0.8206\n",
            "Epoch 39/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6603 - acc: 0.8200\n",
            "Epoch 40/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6452 - acc: 0.8261\n",
            "Epoch 41/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6371 - acc: 0.8258\n",
            "Epoch 42/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6321 - acc: 0.8257\n",
            "Epoch 43/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6394 - acc: 0.8240\n",
            "Epoch 44/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6196 - acc: 0.8289\n",
            "Epoch 45/100\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6061 - acc: 0.8337\n",
            "Epoch 46/100\n",
            "244/484 [==============>...............] - ETA: 2s - loss: 0.5662 - acc: 0.8408"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "budu4qZyUOf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_predictions = 10 \n",
        "print(tokenizer.word_index)\n",
        "predict_sentence = 'nassim'\n",
        "for i in range(1,total_predictions):\n",
        "  sequence_prediction = tokenizer.texts_to_sequences([predict_sentence])[0]\n",
        "  padded_prediction = pad_sequences([sequence_prediction],maxlen = input_length, padding='pre')\n",
        "  prediction = model.predict_classes(padded_prediction)\n",
        "  predicted_word =\"\"\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == prediction : \n",
        "      predicted_word = word\n",
        "      break\n",
        "  predict_sentence += \" \" + predicted_word\n",
        "\n",
        "print(predict_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}